import os
import pandas as pd
import torch
import torch.nn as nn

from datetime import datetime
from airflow import DAG
from airflow.operators.python import PythonOperator
from google.cloud import bigquery
from pymongo import MongoClient

# ====================================================================
# === æ¨¡å‹èˆ‡ BigQuery åƒæ•¸è¨­å®š ===
# ====================================================================

PROJECT_ID = "test123-467809"
DATASET_ID = "bigquery"

TABLE_MAPPING = {
    "05F0287N": "traffic-data-05F0287N",
    "05F0055N": "traffic-data-05F0055N"
}

# å‡è¨­æ¨¡å‹è¨“ç·´æ™‚ä½¿ç”¨çš„æœ€ä½³è¶…åƒæ•¸
input_size = 2
hidden_size = 33
num_layers = 3
output_size = 1
sequence_length = 40

# æ¨¡å‹ä¿å­˜çš„è·¯å¾‘å’Œæª”å
MODEL_SAVE_PATH = '/opt/airflow/lstm_model/best_lstm_model.pth' 

# ====================================================================
# === PyTorch æ¨¡å‹é¡åˆ¥å®šç¾© ===
# ====================================================================
class LSTMModel(nn.Module):
    # ... (æ¨¡å‹é¡åˆ¥å®šç¾©ä¸è®Š)
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

# ====================================================================
# === æ ¸å¿ƒä»»å‹™å‡½å¼ï¼šæ•´åˆæ‰€æœ‰é‚è¼¯ ===
# ====================================================================
def run_all_predictions(**kwargs):
    """
    å°æ‰€æœ‰é–€æ¶åŸ·è¡Œè³‡æ–™æŠ“å–ã€æ¨¡å‹é æ¸¬èˆ‡ MongoDB å„²å­˜ã€‚
    """
    print("æ¨¡å‹é æ¸¬ DAG å·²è¢«è§¸ç™¼ï¼Œé–‹å§‹åŸ·è¡Œé æ¸¬ä»»å‹™ã€‚")
    client_bq = bigquery.Client(project=PROJECT_ID)
    
    # === æ–°å¢ï¼šé€£æ¥ MongoDB ===
    try:
        mongo_client = MongoClient('mongodb', 27017)
        db = mongo_client['traffic_predictions']
        print("æˆåŠŸé€£æ¥åˆ° MongoDBã€‚")
    except Exception as e:
        print(f"é€£æ¥ MongoDB å¤±æ•—ï¼š{e}")
        raise
    
    # è¼‰å…¥æ¨¡å‹
    if not os.path.exists(MODEL_SAVE_PATH):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼š{MODEL_SAVE_PATH}")
    
    loaded_model = LSTMModel(input_size, hidden_size, num_layers, output_size)
    loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))
    loaded_model.eval()
    print("æ¨¡å‹å·²æˆåŠŸè¼‰å…¥ä¸¦è¨­å®šç‚ºè©•ä¼°æ¨¡å¼ã€‚")
    
    for gantry_id, table_name in TABLE_MAPPING.items():
        print("---")
        print(f"æ­£åœ¨è™•ç†é–€æ¶ï¼š{gantry_id}...")
        
        # æ­¥é©Ÿ1: å¾ BigQuery æŠ“å–è³‡æ–™
        query = f"""
            SELECT
                CAST(Avg_speed AS FLOAT64) AS Avg_speed,
                CAST(Total_volume AS INT64) AS Total_volume,
                TimeStamp
            FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}`
            ORDER BY TimeStamp DESC
            LIMIT {sequence_length}
        """
        df = client_bq.query(query).to_dataframe()
        
        if len(df) < sequence_length:
            print(f"âš ï¸ é–€æ¶ {gantry_id} æ•¸æ“šä¸è¶³ {sequence_length} ç­†ï¼Œè·³éé æ¸¬ã€‚")
            continue
        
        df = df.iloc[::-1].reset_index(drop=True)
        
        # æ­¥é©Ÿ2: è³‡æ–™æ¸…æ´—èˆ‡å‰è™•ç† ğŸ§¹
        # ç¢ºä¿è³‡æ–™å‹åˆ¥ç‚ºæ•¸å€¼ï¼Œä¸¦å°‡éæ•¸å€¼è½‰æ›ç‚º NaN
        df['Avg_speed'] = pd.to_numeric(df['Avg_speed'], errors='coerce')
        df['Total_volume'] = pd.to_numeric(df['Total_volume'], errors='coerce')
        
        # æª¢æŸ¥æ˜¯å¦å­˜åœ¨ NaN
        if df.isnull().values.any():
            print(f"è­¦å‘Šï¼šé–€æ¶ {gantry_id} è³‡æ–™ä¸­åŒ…å« NaN å€¼ã€‚")
            # ğŸ’¡ é¸æ“‡ä¸€å€‹è™•ç†ç­–ç•¥ï¼š
            # ç§»é™¤åŒ…å« NaN çš„è³‡æ–™åˆ—
            df.dropna(inplace=True)
            print(f"å·²ç§»é™¤åŒ…å« NaN çš„è³‡æ–™åˆ—ã€‚å‰©é¤˜è³‡æ–™ç­†æ•¸: {len(df)}")
            
        # ç¢ºèªæ¸…æ´—å¾Œè³‡æ–™ç­†æ•¸æ˜¯å¦ä»ç„¶è¶³å¤ 
        if len(df) < sequence_length:
            print(f"âš ï¸ é–€æ¶ {gantry_id} è³‡æ–™æ¸…æ´—å¾Œç­†æ•¸ä¸è¶³ {sequence_length}ï¼Œè·³éé æ¸¬ã€‚")
            continue
        
        # æ­¥é©Ÿ3: æ¨¡å‹é æ¸¬ ğŸ¤–
        latest_features_np = df[['Avg_speed', 'Total_volume']].values[-sequence_length:]
        
        # ğŸ’¡ é‡è¦ï¼šå¼·åˆ¶æŒ‡å®š NumPy é™£åˆ—çš„å‹åˆ¥
        latest_features_np = latest_features_np.astype('float32')
        
        input_for_prediction = torch.tensor(latest_features_np).unsqueeze(0)
        
        with torch.no_grad():
            predicted_speed_tensor = loaded_model(input_for_prediction)
        
        predicted_average_speed = predicted_speed_tensor.squeeze().item()
        print(f"é–€æ¶ {gantry_id} é æ¸¬çš„ä¸‹ä¸€å€‹æ™‚é–“æ­¥å¹³å‡è»Šé€Ÿç‚º: {predicted_average_speed:.2f}")
        
        # === æ­¥é©Ÿ4: å„²å­˜åˆ° MongoDB ===
        # ä½¿ç”¨é–€æ¶ ID ä¾†å‹•æ…‹é¸æ“‡ä¸åŒçš„ Collection
        collection = db[f'predicted_speeds_{gantry_id}']
        
        prediction_record = {
            "gantry_id": gantry_id,
            "predicted_speed": predicted_average_speed,
            "timestamp": datetime.utcnow()
        }
        collection.insert_one(prediction_record)
        print(f"é æ¸¬çµæœå·²æˆåŠŸå„²å­˜è‡³ MongoDBï¼Œé–€æ¶ ID: {gantry_id}ï¼Œé›†åˆåç¨±: {collection.name}")
        
    mongo_client.close()
    print("MongoDB é€£æ¥å·²é—œé–‰ã€‚")

# ====================================================================
# === Airflow DAG è¨­å®š ===
# ====================================================================

with DAG(
    dag_id="traffic_prediction_dag",
    start_date=datetime(2023, 1, 1),
    schedule_interval=None,
    catchup=False,
    tags=['bigquery', 'pytorch', 'prediction'],
) as dag:
    run_all_predictions_task = PythonOperator(
        task_id='run_prediction_for_all_gantries',
        python_callable=run_all_predictions
    )