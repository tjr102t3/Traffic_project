{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa1053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poetry add torch torchvision torchaudio (or pip install torch torchvision torchaudio)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #建構LSTM模型(使用PyTorch)\n",
    " \n",
    " \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隱藏狀態和細胞狀態\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # LSTM 傳播\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # 取最後一個時間步的輸出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 模型參數\n",
    "input_size = 2  # 輸入特徵數量：車速和車流量\n",
    "hidden_size = 33  # 隱藏層大小（可調整的超參數）################## 1\n",
    "num_layers = 3  # LSTM 層數（可調整的超參數）################### 2\n",
    "output_size = 1  # 輸出特徵數量：預測車速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6211b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練集名稱\n",
    "file_name = \"m05a_05F0287N_05F0055N_trainingDataset\"\n",
    "#訓練集所在路徑\n",
    "file_path = r\"D:\\緯育課程\\專題\\TJR102_project\\Data_M05A\\m05a_05F0287N_05F0055N_trainingDataset.csv\" #請替換成自己清理後訓練集(2024)資料的位置\n",
    "\n",
    "#將處理好的資料匯入\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 確保資料是按照時間排序的\n",
    "    # 如果您的資料沒有時間戳記或已確保排序，可以省略這一步\n",
    "    # df = df.sort_values(by='時間戳記') # 假設有時間戳記列\n",
    "\n",
    "    # 將特徵轉換為 PyTorch 張量\n",
    "    # 使用 'Avg_speed' 和 'Total_volume' 為特徵\n",
    "    # 並且Avg_speed是我們要預測的目標變數\n",
    "    features = df[['Avg_speed', 'Total_volume']].values # 輸入特徵\n",
    "    target = df['Avg_speed'].values # 預測目標\n",
    "\n",
    "    # 將 numpy 陣列轉換為 PyTorch 張量\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    target = torch.tensor(target, dtype=torch.float32)\n",
    "    return features, target\n",
    "\n",
    "features, target = load_data(file_path)\n",
    "\n",
    "# 時間序列資料通常需要將資料組織成序列 (sequence) 的形式\n",
    "def create_sequences(features, target, sequence_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(features) - sequence_length):\n",
    "        x = features[i:(i + sequence_length)]\n",
    "        y = target[i + sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "# 使用過去 40 個時間步的資料來預測，例如，使用過去 N 個時間步的資料來預測下一個時間步; 就是學長說的windows(多少個輸入值預測一個輸出值)\n",
    "sequence_length = 40 #時間步長度（可調整的超參數）################## 3\n",
    "X, y = create_sequences(features, target, sequence_length)\n",
    "\n",
    "# 將訓練資料分割成訓練集和驗證集\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02791ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/65], Loss: 3321.9951\n",
      "Epoch [2/65], Loss: 2133.8003\n",
      "Epoch [3/65], Loss: 1350.9557\n",
      "Epoch [4/65], Loss: 820.7831\n",
      "Epoch [5/65], Loss: 574.0102\n",
      "Epoch [6/65], Loss: 380.4660\n",
      "Epoch [7/65], Loss: 238.9210\n",
      "Epoch [8/65], Loss: 255.1575\n",
      "Epoch [9/65], Loss: 201.1940\n",
      "Epoch [10/65], Loss: 225.7889\n",
      "Epoch [11/65], Loss: 225.8472\n",
      "Epoch [12/65], Loss: 250.7917\n",
      "Epoch [13/65], Loss: 81.0407\n",
      "Epoch [14/65], Loss: 14.4840\n",
      "Epoch [15/65], Loss: 8.9532\n",
      "Epoch [16/65], Loss: 10.4659\n",
      "Epoch [17/65], Loss: 5.0741\n",
      "Epoch [18/65], Loss: 7.0192\n",
      "Epoch [19/65], Loss: 3.9650\n",
      "Epoch [20/65], Loss: 3.9339\n",
      "Epoch [21/65], Loss: 3.7816\n",
      "Epoch [22/65], Loss: 7.7098\n",
      "Epoch [23/65], Loss: 2.3503\n",
      "Epoch [24/65], Loss: 3.2127\n",
      "Epoch [25/65], Loss: 7.9650\n",
      "Epoch [26/65], Loss: 5.5338\n",
      "Epoch [27/65], Loss: 3.8213\n",
      "Epoch [28/65], Loss: 4.3955\n",
      "Epoch [29/65], Loss: 3.2846\n",
      "Epoch [30/65], Loss: 3.4099\n",
      "Epoch [31/65], Loss: 5.4585\n",
      "Epoch [32/65], Loss: 2.6513\n",
      "Epoch [33/65], Loss: 3.5236\n",
      "Epoch [34/65], Loss: 2.6098\n",
      "Epoch [35/65], Loss: 7.3066\n",
      "Epoch [36/65], Loss: 3.1792\n",
      "Epoch [37/65], Loss: 3.9168\n",
      "Epoch [38/65], Loss: 2.3279\n",
      "Epoch [39/65], Loss: 7.4513\n",
      "Epoch [40/65], Loss: 3.6909\n",
      "Epoch [41/65], Loss: 6.6478\n",
      "Epoch [42/65], Loss: 5.2069\n",
      "Epoch [43/65], Loss: 3.3315\n",
      "Epoch [44/65], Loss: 2.9259\n",
      "Epoch [45/65], Loss: 5.5670\n",
      "Epoch [46/65], Loss: 3.3403\n",
      "Epoch [47/65], Loss: 3.2156\n",
      "Epoch [48/65], Loss: 4.6263\n",
      "Epoch [49/65], Loss: 4.1582\n",
      "Epoch [50/65], Loss: 4.3022\n",
      "Epoch [51/65], Loss: 4.4968\n",
      "Epoch [52/65], Loss: 6.9524\n",
      "Epoch [53/65], Loss: 4.3019\n",
      "Epoch [54/65], Loss: 3.6083\n",
      "Epoch [55/65], Loss: 4.1302\n",
      "Epoch [56/65], Loss: 4.6149\n",
      "Epoch [57/65], Loss: 4.3590\n",
      "Epoch [58/65], Loss: 5.1379\n",
      "Epoch [59/65], Loss: 4.7035\n",
      "Epoch [60/65], Loss: 3.6163\n",
      "Epoch [61/65], Loss: 6.9425\n",
      "Epoch [62/65], Loss: 3.3381\n",
      "Epoch [63/65], Loss: 6.3625\n",
      "Epoch [64/65], Loss: 5.7381\n",
      "Epoch [65/65], Loss: 4.0318\n"
     ]
    }
   ],
   "source": [
    "# 處理訓練集和驗證集的資料for訓練和評估\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 將資料打包成 TensorDataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 64 # 可調整的超參數 #################### 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 初始化模型、損失函數和優化器\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss() # 常用於回歸任務  # 可調整的超參數############ 5  但這邊就固定使用MSELoss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 優化器  可調整的超參數############ 6   # 學習率 可調整的超參數############ 7\n",
    "\n",
    "epochs = 65 # 可調整的超參數######################## 8\n",
    "\n",
    "# 訓練模型\n",
    "for epoch in range(epochs):\n",
    "    model.train() # 設置模型為訓練模式\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # 前向傳播\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs.squeeze(), batch_y) # outputs.squeeze() 確保形狀匹配\n",
    "\n",
    "        # 反向傳播和優化\n",
    "        optimizer.zero_grad() # 清除之前的梯度\n",
    "        loss.backward() # 計算梯度\n",
    "        optimizer.step() # 更新權重\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 在測試集上評估模型\n",
    "model.eval() # 設置模型為評估模式\n",
    "test_predictions = []\n",
    "test_actuals = []\n",
    "with torch.no_grad(): # 在評估時禁用梯度計算\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        test_predictions.extend(outputs.squeeze().tolist())\n",
    "        test_actuals.extend(batch_y.tolist())\n",
    "\n",
    "# 將預測結果轉換為 numpy 陣列以便計算 MAPE\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_actuals = np.array(test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2755485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試集 MAPE: 2.30%\n"
     ]
    }
   ],
   "source": [
    "# 計算MAPE\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    計算平均絕對百分比誤差 (MAPE)\n",
    "    y_true: 實際值 (numpy array)\n",
    "    y_pred: 預測值 (numpy array)\n",
    "    \"\"\"\n",
    "    # 避免除以零的情況，可以設定一個非常小的值作為分母的下限\n",
    "    # 或者濾掉 y_true 為零的點，因為對於車速來說，通常不會是零\n",
    "    # 根據實際情況選擇處理方式\n",
    "    \n",
    "    # 這裡我們濾掉 y_true 為零的點，因為 MAPE 在實際值為零時無意義\n",
    "    non_zero_indices = y_true != 0\n",
    "    y_true_filtered = y_true[non_zero_indices]\n",
    "    y_pred_filtered = y_pred[non_zero_indices]\n",
    "    \n",
    "    if len(y_true_filtered) == 0:\n",
    "        return float('inf') # 如果沒有非零的實際值，MAPE 無法計算\n",
    "\n",
    "    return np.mean(np.abs((y_true_filtered - y_pred_filtered) / y_true_filtered)) * 100\n",
    "\n",
    "# 計算測試集上的 MAPE\n",
    "mape = mean_absolute_percentage_error(test_actuals, test_predictions)\n",
    "print(f'測試集 MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39dccba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存至: best_lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 保存訓練好的模型\n",
    "\n",
    "\n",
    "# 定義模型保存的路徑和檔名\n",
    "model_save_path = 'best_lstm_model.pth'\n",
    "\n",
    "# 保存模型的狀態字典\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"模型已保存至: {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tjr102-project-sDjiclj--py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
